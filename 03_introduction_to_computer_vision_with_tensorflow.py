# -*- coding: utf-8 -*-
"""03_introduction_to_computer_vision_with_tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bvym9DlP4PaRozkcULaZblL3an6gMF7P

Computer vision is a practice of writing algorithms which can discover patterns in visual data such as the camera of a self-driving car recognizeing a car in front.
"""

#Get the data 
import zipfile

!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip

#Unzip the downloading file 
zip_ref = zipfile.ZipFile("pizza_steak.zip")
zip_ref.extractall()
zip_ref.close()

#See the data 
!ls pizza_steak

!ls pizza_steak/train/steak

import os 

#Walk through the pizza_steak directory and list the number of files 

for dirpath, dirnames, filenames in os.walk("pizza_steak"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'")

#Another way to find out how many images are in a file 
num_steak_images_train = len(os.listdir("pizza_steak/train/steak"))
num_steak_images_train

#Visualize out images, get the classnames programmatically 
import pathlib 
import numpy as np 
data_dir = pathlib.Path("pizza_steak/train")
class_names = np.array(sorted([item.name for item in data_dir.glob("*")]))
class_names = class_names[:]
print(class_names)

#Visualize images 
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random 

def view_random_image(target_dir, target_class):
  #Setup the target directory and we'll view images
  target_folder = target_dir+target_class

  #Get a random image path 
  random_image = random.sample(os.listdir(target_folder),1)
  print(random_image)


  #Read the image and plot it 
  img = mpimg.imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off")
  #Show the image
  print(f"Image shape: {img.shape}") 

  return img

#View random image from the training dataset 
img = view_random_image(target_dir="pizza_steak/train/",
                        target_class="steak")

img = view_random_image(target_dir="pizza_steak/train/",
                        target_class="pizza")

#Viewing the image as a tensor 
import tensorflow as tf
tf.constant(img)

#View the image shape 
img.shape #return width,height and color channels

#Normalize the data 
img = img/255.0
img

"""#An end-to-end example 
Building a convolutional neural network to find patterns in our images. 
* Load images 
* Preprocess our images 
* Build a CNN to find patterns in our image
* Compile our CNN
* Fit the CNN to our training data 
"""

import tensorflow as tf 
from tensorflow.keras.preprocessing.image import ImageDataGenerator

tf.random.set_seed(42)

#Preprocess data (Get all the pixel value between 0 and 1)
train_datagen = ImageDataGenerator(rescale = 1./255) 
valid_datagen = ImageDataGenerator(rescale = 1./255)

#Setup paths to our directories
train_dir = "pizza_steak/train"
test_dir = "pizza_steak/test"

#Import data from directories and turn it into batches 
train_data = train_datagen.flow_from_directory(directory = train_dir,
                                               batch_size = 32,
                                               target_size = (224,224),
                                               class_mode = "binary",
                                               seed = 42)

valid_data = valid_datagen.flow_from_directory(directory = test_dir,
                                               batch_size = 32,
                                               target_size = (224,224),
                                               class_mode = "binary",
                                               seed = 42)

#Build the CNN model!!!
model_1 = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(filters = 10,
                           kernel_size = 3,
                           activation = "relu",
                           input_shape = (224,224,3)),
    tf.keras.layers.Conv2D(10,3,activation="relu"),
    tf.keras.layers.MaxPool2D(pool_size = 2,
                              padding="valid"),
    tf.keras.layers.Conv2D(10,3,activation="relu"),
    tf.keras.layers.Conv2D(10,3,activation="relu"),
    tf.keras.layers.MaxPool2D(2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1,activation = "sigmoid")# 3 is for the color channels 
])


#Compile the CNN model 
model_1.compile(loss = tf.keras.losses.BinaryCrossentropy(),
                optimizer = tf.keras.optimizers.Adam(),
                metrics = ["accuracy"])

#Fit the model 
history_1 = model_1.fit(train_data,
                        epochs = 10,
                        steps_per_epoch = len(train_data),
                        validation_data = valid_data,
                        validation_steps = len(valid_data))

model_1.summary()

#Using the same model in the classification with the images dataset 


#Tweaked the model a little because the accuracy was 50% 
tf.random.set_seed(42)

model_2 = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(224,224,3)),
    tf.keras.layers.Dense(100,activation="relu"),
    tf.keras.layers.Dense(100,activation="relu"),
    tf.keras.layers.Dense(100,activation="relu"),
    tf.keras.layers.Dense(100,activation="relu"),
    tf.keras.layers.Dense(1,activation="sigmoid")
])

model_2.compile(loss = tf.keras.losses.BinaryCrossentropy(),
                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),
                metrics = ["accuracy"])

model_2.fit(train_data,
            epochs=10,
            steps_per_epoch = len(train_data),
            validation_data = valid_data,
            validation_steps = len(valid_data))

model_2.summary()

"""#Lets break down the binary classification 
1. Become one with data (Visualize it)
2. Preprocess the data (normalize and turn the data into batches)
3. Create a model 
4. Fit the model
5. Evaluate the model 
6. Adjust different parameters and improve the model
7. Repeat until satsfied 
"""

#1. Become one with the data 
plt.figure()
plt.subplot(1,2,1)
steak_img = view_random_image("pizza_steak/train/", "steak")
plt.subplot(1,2,2)
pizza_img = view_random_image("pizza_steak/train/", "pizza")

#2. Preprocess the data 
#Lets define the directory dataset paths 

train_dir = "pizza_steak/train/"
test_dir = "pizza_steak/train/"

#Turn the data into batches 
#A batch is a small subset of the data. Rather than looking at all the data at one time, a model might only look at 32 at a time
#It does this because: 
#1. All the data might not fit into the memory of the GPU
#2. Trying to learn the patterns in all the data in one hit, could result in the model not being able to learn well.


#Lets train and test data generators and rescale the data 

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale = 1/255.)
test_datagen = ImageDataGenerator(rescale = 1/255.)

#Lets load the image data from directories and turn them into batches 

train_data = train_datagen.flow_from_directory(directory = train_dir, # The directory you want the images to be loaded
                                               target_size = (224,224), # Defaults to 256,256
                                               class_mode = "binary") # Type of data (Optimizers!!)) # Put them into batches of 32

test_data = test_datagen.flow_from_directory(directory = test_dir,
                                             batch_size = (224,224),
                                             class_mode = "binary")


#Get a sample of the train data batch 
images, labels = train_data.next()
len(images), len(labels)

#How many batches are there 
len(train_data)

#Get the first two images of the first batch 
images[2], images[0].shape

#Create a CNN model (start with a baseline)

from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation
from tensorflow.keras import Sequential
import tensorflow as tf
model_4 = Sequential([
  Conv2D(filters=10, 
         kernel_size=(3,3), 
         strides=(1,1),
         padding='valid',
         activation='relu', 
         input_shape=(224, 224, 3)), # input layer (specify input shape)
  Conv2D(10, 3, activation='relu'),
  Conv2D(10, 3, activation='relu'),
  Flatten(),
  Dense(1, activation='sigmoid') # output layer (specify output shape)
])

model_4.compile(loss='binary_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])
     
model_4.summary()

# history_4 = model_4.fit(train_data,
#                         epochs=5

#Evaluating the model by plotting it!!
import pandas as pd 
pd.DataFrame(history_4.history).plot(figsize=(10,7))

import matplotlib.pyplot as plt
def plot_loss_curves(history):
  """
  Returns separate loss curves for training and validation metrics.
  """ 
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']

  epochs = range(len(history.history['loss']))

  # Plot loss
  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  # Plot accuracy
  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend();

plot_loss_curves(history_4)

"""When a models validdation loss starts to increase, it's likely that the model is overfitting the training data set

Ways to induce overfitting: 
* Increase the number of conv layers
* Increase the number of conv filters
* Add another dense layer to the output of our flattened layer


Ways to reduce overfitting: 
* Add data augmentation
* Add regularization
* Add more data 
"""

#Create the model( this is the new baseline )
from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation
from tensorflow.keras import Sequential
import tensorflow as tf


tf.random.set_seed(42)

#Preprocess data (Get all the pixel value between 0 and 1)
train_datagen = ImageDataGenerator(rescale = 1./255)
valid_datagen = ImageDataGenerator(rescale = 1./255)

#Setup paths to our directories
train_dir = "pizza_steak/train"
test_dir = "pizza_steak/test"

#Import data from directories and turn it into batches 
train_data = train_datagen.flow_from_directory(directory = train_dir,
                                               batch_size = 32,
                                               target_size = (224,224),
                                               class_mode = "binary",
                                               seed = 42)

valid_data = valid_datagen.flow_from_directory(directory = test_dir,
                                               batch_size = 32,
                                               target_size = (224,224),
                                               class_mode = "binary",
                                               seed = 42)
model_5 = Sequential([
    Conv2D(10,3,activation="relu"),
    MaxPool2D(pool_size=2),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Flatten(),
    Dense(1,activation="sigmoid")
])

model_5.compile(loss = "binary_crossentropy",
                optimizer = Adam(),
                metrics = ["accuracy"])

history_5 = model_5.fit(train_data,
                        epochs = 5,
                        steps_per_epoch = len(train_data),
                        validation_data = valid_data,
                        validation_steps = len(valid_data))
# test_data.shape

model_5.summary()

train_datagen_augmented = ImageDataGenerator(rescale = 1/255.,
                                             rotation_range = 0.2,
                                             shear_range = 0.2,
                                             zoom_range = 0.2,
                                             width_shift_range =0.2,
                                             height_shift_range = 0.3,
                                             horizontal_flip = True)


train_datagen = ImageDataGenerator(rescale = 1/255.)

test_datagen = ImageDataGenerator(rescale = 1/255.)

#Import data and augment it from traiing directory
print("Augmented training data")

train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,
                                            target_size = (224,224),
                                            class_mode = "binary",
                                            shuffle = False)

print("Non-augmented training data ")
train_data = train_datagen.flow_from_directory(train_dir,
                                               target_size = (224,224),
                                               class_mode = "binary",
                                               shuffle = False)


print("Non-augmented test data")
test_data = test_datagen.flow_from_directory(test_dir,
                                            target_size = (224,224),
                                            class_mode = "binary",
                                            shuffle = False)

"""Data augmentation is usually performed on the trainig data.
Using ImageDataGenerator built-in data augmentation parameters our images are left as they are in the directories but are modified as they are loaded in the model.
"""

#Visualizing some augmented data 
images,labels = train_data.next()
augmented_images,augmented_labels = train_data_augmented.next()

import random
random_number = random.randint(0,32)
plt.imshow(images[random_number])

plt.figure()
plt.imshow(augmented_images[random_number])

#Create model that is trained on augmented training data!!
model_6 = Sequential([
    Conv2D(10,3,activation="relu"),
    MaxPool2D(pool_size = 2),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Flatten(),
    Dense(1,activation = "sigmoid")
])

model_6.compile(loss = "binary_crossentropy",
                optimizer = Adam(),
                metrics = ["accuracy"])

model_6.fit(train_data_augmented,
            epochs = 5,
            steps_per_epoch = len(train_data_augmented),
            validation_data = test_data,
            validation_steps = len(test_data))

print("Augmented data with shuffle")
train_data_augmented_shuffle = train_datagen_augmented.flow_from_directory(train_dir,
                                                                           target_size = (224,224),
                                                                           class_mode = "binary")

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D,Flatten,Dense
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

model_7 = Sequential([
    Conv2D(10,3,activation="relu", input_shape =(224,224,3)),
    MaxPool2D(pool_size = 2),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Flatten(),
    Dense(1,activation = "sigmoid")
])
model_7.compile(loss = "binary_crossentropy",
                optimizer = Adam(),
                metrics = ["accuracy"])
model_7.fit(train_data_augmented_shuffle,
            epochs = 5)

print(class_names)

#View our example image 
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg
steak = mpimg.imread("03-steak.jpeg")
plt.imshow(steak)
plt.axis(False)

steak

#Create a function to import the image and resize it to be used with the model 
def load_and_prep_image(filename,img_shape = 224):

  #Read the image 
  img = tf.io.read_file(filename)

  #Decode the read file into a tensor
  img = tf.image.decode_image(img)

  #Resize the image
  img = tf.image.resize(img,size = [img_shape,img_shape])

  #Rescale the image (get all values between 0 and 1)
  img = img/255.
  return img

#Load in and preprocess our custom image 
steak = load_and_prep_image("03-steak.jpeg")
steak

expanded_steak = tf.expand_dims(steak,axis = 0)
pred = model_7.predict(expanded_steak)

#Lets transform the prediction probability shown in the above result (0.9535...) to the class_names
#We can index the predicted class by rounding the prediction probablity 
pred_class = class_names[int(tf.round(pred))]
pred_class

def pred_and_plot(model,filename,class_names = class_names):
  #Import the target image and preprocess it 
  img = load_and_prep_image(filename)

  #Make a prediction
  pred = model.predict(tf.expand_dims(img,axis=0))

  #Get the predicted class
  pred_class = class_names[int(tf.round(pred))]

  #Plot the image and the predicted class 
  plt.imshow(img)
  plt.title(f"Prediction:{pred_class}")
  plt.axis(False)



pred_and_plot(model_7,"03-steak.jpeg")

!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg
pred_and_plot(model_7,"03-pizza-dad.jpeg")

#Wrong prediction!!!

steak = load_and_prep_image("03-pizza-dad.jpeg")
steak

expanded_steak = tf.expand_dims(steak,axis = 0)
pred = model_7.predict(expanded_steak)
pred

"""Multi-class Image Classification:

Lets create a model that learns from 10 classes
1. Become one with the data
2. Preprocess the data 
3. Create a model
4. Fit the model (overfit it to make sure it works)
5. Evaluate the model
6. Adjust different hyperparameters and improve the model
7. Repeat until satisfied

> Indented block


"""

#Import zipfile 
import zipfile 
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip
#Unzip our data 
zip_ref = zipfile.ZipFile("10_food_classes_all_data.zip","r")
zip_ref.extractall()
zip_ref.close()

import os 
for dirpath,dirnames,filenames in os.walk("10_food_classes_all_data"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'")

#Setup the train adn test directories 
train_dir = "10_food_classes_all_data/train/"
test_dir = "10_food_classes_all_data/test/"

#Lets get the class names 
import pathlib 
import numpy as np
data_dir = pathlib.Path(train_dir)
class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))
class_names

#Visualize 
import random
img = view_random_image(target_dir = train_dir,
                        target_class = random.choice(class_names))

from tensorflow.keras.preprocessing.image import ImageDataGenerator 
#Rescale 
train_datagen = ImageDataGenerator(rescale = 1/255.)
test_datagen = ImageDataGenerator(rescale = 1/255.)

#Load data from directories and turn them into batches 
train_data = train_datagen.flow_from_directory(train_dir,
                                               target_size = (224,224),
                                               batch_size = 32,
                                               class_mode = 'categorical')
test_data = test_datagen.flow_from_directory(test_dir,
                                             target_size = (224,224),
                                             batch_size = 32,
                                             class_mode = 'categorical')

from tensorflow.keras import Sequential 
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam 
import tensorflow as tf 

model_8 = Sequential([
    Conv2D(10,3,activation="relu",input_shape=(224,224,3)),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Flatten(),
    Dense(10,activation = "softmax")

])


model_8.compile(loss = "categorical_crossentropy",
                optimizer = Adam(),
                metrics = ["accuracy"])


history_8 = model_8.fit(train_data,
            epochs = 5,
            steps_per_epoch = len(train_data),
            validation_data = test_data,
            validation_steps = len(test_data))

model_8.evaluate(test_data)

#Lets check out the model's loss curves 
plot_loss_curves(history_8)

#This model shows its overfitting. Let's fix it!!
# 1. Get More data 
# 2. Simplify the model 
# 3. Use data augmentation
# 4. Use transfer learning

#lets simplify the model 
model_8.summary()

#Lets remove 2 convulational layers 
model_9 = Sequential([
    Conv2D(10,3,activation="relu",input_shape=(224,224,3)),
    MaxPool2D(),
    Conv2D(10,3,activation="relu"),
    MaxPool2D(),
    Flatten(),
    Dense(10,activation="softmax")
])

model_9.compile(loss = "categorical_crossentropy",
                optimizer = Adam(),
                metrics = ["accuracy"])

history_9 = model_9.fit(train_data,
            epochs = 5,
            steps_per_epoch = len(train_data),
            validation_data = test_data,
            validation_steps = len(test_data))

plot_loss_curves(history_9)
#No difference in the loss curves!!!!

#Let's try data augmentation!!

#create an augmented data generator instance 
train_datagen_augmented = ImageDataGenerator(rescale=1/255.,
                                             rotation_range = 0.2,
                                             width_shift_range = 0.2,
                                             height_shift_range = 0.2,
                                             zoom_range = 0.2,
                                             horizontal_flip = True)
 
train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,
                                                                   target_size = (224,224),
                                                                   class_mode = "categorical")

#Lets create another model and lets fit it with the agmented data 
model_10 = tf.keras.models.clone_model(model_8)

model_10.compile(loss = "categorical_crossentropy",
                 optimizer = Adam(),
                 metrics = ["accuracy"])


history_10 = model_10.fit(train_data_augmented,
             epochs = 20,
             steps_per_epoch = len(train_data_augmented),
             validation_data = test_data,
             validation_steps = len(test_data))

plot_loss_curves(history_10)

#Lets make predictions on custom images!!
#Lets download some custom images!!


!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg
!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-hamburger.jpeg
!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-sushi.jpeg
!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg

#Reconfig pred and plot function to work with multi class images 
def pred_and_plot(model,filename,class_names = class_names):
  #Import the target image and preprocess it 
  img = load_and_prep_image(filename)

  #Make a prediction
  pred = model.predict(tf.expand_dims(img,axis=0))

  #Logic for multiclass 
  if len(pred[0]) > 1:
    pred_class = class_names[tf.argmax(pred[0])]
  else:
    pred_class = class_names[int(tf.round(pred))]
  
  #Plot the image and the predicted class 
  plt.imshow(img)
  plt.title(f"Prediction:{pred_class}")
  plt.axis(False)

pred_and_plot(model = model_10, 
              filename = "03-pizza-dad.jpeg",
              class_names = class_names)

pred_and_plot(model = model_10, 
              filename = "03-hamburger.jpeg",
              class_names = class_names)

pred_and_plot(model = model_10, 
              filename = "03-sushi.jpeg",
              class_names = class_names)

pred_and_plot(model = model_10, 
              filename = "03-steak.jpeg",
              class_names = class_names)

#Saving and loading the model!!

#Save a model 
model_10.save("Saved_Trained_Model_10")

#Load in the trained model
loaded_model = tf.keras.models.load_model("Saved_Trained_Model_10")
loaded_model.evaluate(test_data)

model_10.evaluate(test_data)

